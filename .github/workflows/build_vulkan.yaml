name: Run in Docker Container

on:
  workflow_dispatch:
    inputs:
      quantization:
        description: "Choose quantization for model"
        required: true
        default: "q0f32"
        type: choice
        options:
          - q0f32
          - q4f16

jobs:
  run-in-container:
    runs-on: ubuntu-latest
    container:
      image: olyasir/models_build:ubuntu22.04_vulkan

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Run a command in the container
        run: |
          echo "Running inside Docker container from Docker Hub"
          python --version
          vulkaninfo
          pwd 

      - name: Doownload model
        run: curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash && \
             apt-get install git-lfs && \
             git-lfs install && git clone https://huggingface.co/Helsinki-NLP/opus-mt-en-it

      - name: Create build directory
        run: mkdir build && cd build && cp ../cmake/config.cmake . && cmake ..

      - name: Build the project
        run: |
           cd build && cmake --build . 

      - name: Install mlc-llm
        run: |
           cd python && pip install -e .

      - name: Compile model
        run: |
            ./ci/models_build/marian.sh

      - name: Upload compied model as artifact
        uses: actions/upload-artifact@v3
        with:
          name: output-q0f32-opus-mt-en-it
          path: output-q0f32-opus-mt-en-it/
            
