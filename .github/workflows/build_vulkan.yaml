name: Compile Marian model

on:
  workflow_dispatch:
    inputs:
      quantization:
        description: "Choose quantization for model"
        required: true
        default: "q0f32"
        type: choice
        options:
          - q0f32
          - q4f16

jobs:
  run-in-container:
    runs-on: ubuntu-latest
    container:
      image: olyasir/models_build:ubuntu22.04_vulkan

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable  # You can specify other toolchains like 'nightly' if needed
          override: true

      - name: Mark repository as safe
        run: |
          git config --global --add safe.directory /__w/mlc-llm/mlc-llm

      - name: get submodules
        run: |
            git submodule update --init --recursive

      - name: Run a command in the container
        run: |
          echo "Verifying vulkan instalation "
          python --version
          vulkaninfo
          cargo --version
          pwd 

    

      - name: Download model
        run: git-lfs install && git clone https://huggingface.co/Helsinki-NLP/opus-mt-en-it

      - name: Create build directory
        run: mkdir build && cd build && cp ../cmake/config.cmake . && cmake ..

      - name: Build the project
        run: |
           cd build && cmake --build . 

      - name: Install mlc-llm
        run: |
           cd python && pip install -e .

      - name: Compile model
        run: |
            ./ci/models_build/marian.sh

      - name: Upload compied model as artifact
        uses: actions/upload-artifact@v3
        with:
          name: output-q0f32-opus-mt-en-it
          path: output-q0f32-opus-mt-en-it/
            
